import os
import sys
import cv2
import torch
import pickle
import numpy as np
from tqdm import tqdm
from PIL import Image
import clip
from transnetv2 import TransNetV2

# âœ… å¯¼å…¥å…³é”®å¸§æå–å‡½æ•°
current_dir = os.path.dirname(os.path.abspath(__file__))
extraction_dir = os.path.abspath(os.path.join(current_dir, "../Keyframe-Extraction-for-video-summarization-main/src/extraction"))
sys.path.append(extraction_dir)
# print("æ¨¡å—æœç´¢è·¯å¾„ï¼š", extraction_dir)
from Keyframe_extraction import scen_keyframe_extraction
# from save_keyframe import save_frames_by_index_memory_cached

# ---------- å‚æ•°é…ç½® ----------
# video_path = os.path.join(current_dir, "test.mp4")
video_path = os.path.abspath(os.path.join(current_dir, "../movement/fixed_test.mp4"))
print("ğŸ¯ æ­£åœ¨ä½¿ç”¨è§†é¢‘è·¯å¾„ï¼š", video_path)
output_dir = os.path.join(current_dir, "lmske_intermediate")
scenes_path = os.path.join(output_dir, "scene_list.txt")
features_npy_path = os.path.join(output_dir, "features.npy")
features_pkl_path = os.path.join(output_dir, "features.pkl")  # ä¸ºå…¼å®¹åŸé€»è¾‘
frames_list_path = os.path.join(output_dir, "frames_list.pkl")
keyframe_pkl_path = os.path.join(output_dir, "keyframe_indices.pkl")
keyframe_img_folder = os.path.join(current_dir, "keyframes_output")

os.makedirs(output_dir, exist_ok=True)
os.makedirs(keyframe_img_folder, exist_ok=True)

device = "cuda" if torch.cuda.is_available() else "cpu"

# ---------- Step 1ï¼šé•œå¤´æ£€æµ‹ ----------
def detect_scenes():
    print("ğŸ¬ Step 1: Running TransNetV2...")
    model = TransNetV2()
    video_frames, single_frame_predictions, _ = model.predict_video(video_path)
    scene_list = model.predictions_to_scenes(single_frame_predictions)

    with open(scenes_path, "w") as f:
        for start, end in scene_list:
            f.write(f"{start} {end}\n")

    print(f"âœ… é•œå¤´æ£€æµ‹å®Œæˆï¼Œå…± {len(scene_list)} æ®µï¼Œå·²ä¿å­˜è‡³ {scenes_path}")
    return scene_list

# ---------- Step 2ï¼šæå–å¸§ç‰¹å¾ ----------
def extract_clip_features():
    print("ğŸ§  Step 2: æå–è§†é¢‘å¸§è¯­ä¹‰ç‰¹å¾ï¼ˆCLIPï¼‰...")
    model, preprocess = clip.load("ViT-B/32", device=device)
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    features = []
    frame_indices = []

    for i in tqdm(range(total_frames), desc="æå–ä¸­"):
        ret, frame = cap.read()
        if not ret:
            break

        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        img_pre = preprocess(img).unsqueeze(0).to(device)

        with torch.no_grad():
            embedding = model.encode_image(img_pre).cpu().numpy().squeeze()

        features.append(embedding)
        frame_indices.append(i)

    cap.release()

    np.save(features_npy_path, np.array(features))
    with open(frames_list_path, "wb") as f:
        pickle.dump(frame_indices, f)

    # ä¸ºå…¼å®¹ Keyframe_extraction åŸé€»è¾‘ï¼Œå­˜ä¸€ä»½ .pkl ç‰¹å¾
    with open(features_pkl_path, "wb") as f:
        pickle.dump(features, f)

    print(f"âœ… ç‰¹å¾æå–å®Œæˆï¼Œå…± {len(features)} å¸§")

# ---------- Step 3&4ï¼šæå–å…³é”®å¸§ ----------
def run_keyframe_extraction():
    print("ğŸ§© Step 3: å¼€å§‹å…³é”®å¸§èšç±»æå–...")
    scen_keyframe_extraction(
        scenes_path=scenes_path,
        features_path=features_pkl_path,
        video_path=video_path,
        save_path=keyframe_pkl_path,
        folder_path=keyframe_img_folder,
        frames_list_path="lmske_intermediate/frames_list.pkl"
    )
    # if os.path.exists(keyframe_img_folder) and os.listdir(keyframe_img_folder):
    #     print("âœ… Step 4: æå–å®Œæˆï¼Œå…³é”®å¸§ä¿å­˜åœ¨:", keyframe_img_folder)
    # else:
    #     print("âš ï¸ Step 4ï¼šæ²¡æœ‰ä¿å­˜ä»»ä½•å…³é”®å¸§ï¼Œè¯·æ£€æŸ¥æå–é€»è¾‘æˆ–ä¿å­˜è·¯å¾„ã€‚")
    

# def save_keyframes_from_pkl(keyframe_pkl, frames_list_pkl, video_path, output_folder):
#     with open(keyframe_pkl, "rb") as f:
#         keyframe_indices = pickle.load(f)
#     print(f"ğŸ”¢ åŠ è½½å…³é”®å¸§ç¼–å·ï¼Œå…± {len(keyframe_indices)} å¼ ")
#     print("âœ”ï¸ å…³é”®å¸§ç´¢å¼•ç¤ºä¾‹ï¼š", keyframe_indices[:5])

#     save_frames_by_index_memory_cached(
#         keyframe_indexes=keyframe_indices,
#         video_path=video_path,
#         folder_path=output_folder,
#         frames_list_path=frames_list_pkl
#     )

# ---------- æ‰§è¡Œæµç¨‹ ----------
if __name__ == "__main__":
    if not os.path.exists(video_path):
        print(f"âŒ æœªæ‰¾åˆ°è§†é¢‘ï¼š{video_path}")
        sys.exit()

    detect_scenes()
    extract_clip_features()
    run_keyframe_extraction()
    # save_keyframes_from_pkl(
    #     keyframe_pkl=keyframe_pkl_path,
    #     frames_list_pkl=frames_list_path,
    #     video_path=video_path,
    #     output_folder=keyframe_img_folder
    # )